{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7c8fb7e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/11/06 09:50:47 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "from pyspark import SparkContext, SparkConf\n",
    "conf = SparkConf().setMaster('spark://master:7077').setAppName('WordCount')\n",
    "sc = SparkContext(conf=conf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d3ad36b0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('spark.driver.extraJavaOptions',\n",
       "  '-XX:+IgnoreUnrecognizedVMOptions --add-opens=java.base/java.lang=ALL-UNNAMED --add-opens=java.base/java.lang.invoke=ALL-UNNAMED --add-opens=java.base/java.lang.reflect=ALL-UNNAMED --add-opens=java.base/java.io=ALL-UNNAMED --add-opens=java.base/java.net=ALL-UNNAMED --add-opens=java.base/java.nio=ALL-UNNAMED --add-opens=java.base/java.util=ALL-UNNAMED --add-opens=java.base/java.util.concurrent=ALL-UNNAMED --add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.cs=ALL-UNNAMED --add-opens=java.base/sun.security.action=ALL-UNNAMED --add-opens=java.base/sun.util.calendar=ALL-UNNAMED --add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED'),\n",
       " ('spark.app.startTime', '1667728247021'),\n",
       " ('spark.master', 'spark://master:7077'),\n",
       " ('spark.driver.host', 'master'),\n",
       " ('spark.executor.id', 'driver'),\n",
       " ('spark.driver.port', '41137'),\n",
       " ('spark.rdd.compress', 'True'),\n",
       " ('spark.executor.extraJavaOptions',\n",
       "  '-XX:+IgnoreUnrecognizedVMOptions --add-opens=java.base/java.lang=ALL-UNNAMED --add-opens=java.base/java.lang.invoke=ALL-UNNAMED --add-opens=java.base/java.lang.reflect=ALL-UNNAMED --add-opens=java.base/java.io=ALL-UNNAMED --add-opens=java.base/java.net=ALL-UNNAMED --add-opens=java.base/java.nio=ALL-UNNAMED --add-opens=java.base/java.util=ALL-UNNAMED --add-opens=java.base/java.util.concurrent=ALL-UNNAMED --add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.cs=ALL-UNNAMED --add-opens=java.base/sun.security.action=ALL-UNNAMED --add-opens=java.base/sun.util.calendar=ALL-UNNAMED --add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED'),\n",
       " ('spark.app.name', 'WordCount'),\n",
       " ('spark.serializer.objectStreamReset', '100'),\n",
       " ('spark.submit.pyFiles', ''),\n",
       " ('spark.submit.deployMode', 'client'),\n",
       " ('spark.app.submitTime', '1667728246711'),\n",
       " ('spark.app.id', 'app-20221106095049-0000'),\n",
       " ('spark.ui.showConsoleProgress', 'true')]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sc.setLogLevel('ERROR')\n",
    "sc.version\n",
    "sc.getConf().getAll()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fd0a9a9",
   "metadata": {},
   "source": [
    "1. Count the number of times a word appears in the file  \n",
    "First, we remove all the special characters with regex library, remove trailing spaces and lower case all characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "43024d76",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/vagrant/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import math\n",
    "import time \n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "def removePunctuation(text):\n",
    "    # Convert all text to lower case, remove any punctuation, remove leading and trailing spaces\n",
    "    return (\n",
    "        re\n",
    "        .sub(r'[^A-Za-z0-9 ]', '', text)\n",
    "        .strip()\n",
    "        .lower()\n",
    "    )\n",
    "\n",
    "stopwordsList = stopwords.words('english')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "349a0925",
   "metadata": {},
   "source": [
    "Then we load the text file into RDD  \n",
    "Apply flatMap to map each line to a list of words and remove all the stop words\n",
    "Map each word into a tuple with the key is a word and value 1  \n",
    "Use ReduceByKey to sum all the value with the same key  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5c9407dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "wordCountRDD = (\n",
    "    sc\n",
    "#     .textFile('data/1B.language.model.test.txt', 8)\n",
    "    .textFile('data/1B.language.model.txt', 8)\n",
    "    .map(removePunctuation)\n",
    "    .flatMap(lambda line: line.split())\n",
    "    .filter(lambda word: word not in stopwordsList)\n",
    "    .map(lambda x: (x, 1))\n",
    "    .reduceByKey(lambda a, b: a + b)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7b9252ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('said', 4308248), ('would', 1531729), ('new', 1488263), ('one', 1462455), ('us', 1238052), ('also', 1223178), ('year', 1139189), ('two', 1119560), ('people', 1100102), ('last', 1077763), ('first', 1034435), ('mr', 904485), ('years', 873666), ('could', 868860), ('time', 852404)]\n",
      "--- 1312.7914786338806 seconds ---\n"
     ]
    }
   ],
   "source": [
    "# Print result\n",
    "start_time = time.time()\n",
    "print(wordCountRDD.takeOrdered(15, lambda x: -x[1]))\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e740e8a",
   "metadata": {},
   "source": [
    "2. Calculate the most common words in the file  \n",
    "Apply max method to the RDD to get the tuple with maximum value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b03977c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 3:=====================================================> (120 + 4) / 124]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('said', 4308248)\n",
      "--- 14.639453887939453 seconds ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "print(wordCountRDD.max(key=lambda x:x[1]))\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0213510",
   "metadata": {},
   "source": [
    "3. Calculate the average number of appearances of all words.  \n",
    "First we calculate the total number of apprearances of each word by summing all values from all tuples\n",
    "Then we divide it to the total number of words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9ddfae42",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 7:======================================================>(122 + 2) / 124]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "204.13156518735002\n",
      "--- 25.568430423736572 seconds ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "print(\n",
    "    wordCountRDD\n",
    "    .map(lambda x: x[1])\n",
    "    .reduce(lambda a, b: a + b) \n",
    "    / \n",
    "    wordCountRDD\n",
    "    .count()\n",
    ")\n",
    "end_time = time.time()\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bb10e07",
   "metadata": {},
   "source": [
    "4. Calculate the frequency of combination of two words appears in the text file.  \n",
    "The first step is also apply the removePunctuation filtering.  \n",
    "Then we use flatMap to map each line into list of string, each string includes two consecutive words seperate with a space, and map the result into tuple of value 1  \n",
    "Apply reduceByKey to sum up the values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b272bc12",
   "metadata": {},
   "outputs": [],
   "source": [
    "twoWordCountRDD = (\n",
    "    sc\n",
    "#     .textFile('data/1B.language.model.test.txt', 8)\n",
    "    .textFile('data/1B.language.model.txt', 8)\n",
    "    .map(removePunctuation)\n",
    "    .flatMap(lambda line: list(map(' '.join, zip( line.split()[:-1],  line.split()[1:]))))\n",
    "    .map(lambda x: (x, 1))\n",
    "    .reduceByKey(lambda a, b: a + b)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5d85565a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 9:>                                                          (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('force was', 1850), ('fierce rearguard', 6), ('loser doesn', 7), ('cent blaming', 9), ('for interesting', 123), ('the superhero', 294), ('dubai world', 3113), ('left by', 3539), ('egg morning', 1), ('the sector', 8693), ('apartment will', 38), ('eruption of', 636), ('and within', 3020), ('the emea', 122), ('case the', 9009), ('major parties', 892), ('entertainment tonight', 533), ('streets of', 11202), ('with posters', 262), ('the target', 10397), ('of this', 136235), ('a car', 34886), ('conditions and', 6810), ('that doesn', 10807), ('match for', 2579), ('without sacrificing', 443), ('pro seasons', 32), ('his staff', 4678), ('polls and', 2176), ('bbc the', 1169), ('you unnecessarily', 1), ('opportunities to', 5086), ('missile defense', 5305), ('the brink', 7562), ('college though', 27), ('lawsuit was', 1149), ('months or', 2695), ('georgian and', 265), ('smog the', 16), ('a vacancy', 513), ('say the', 55571), ('her partner', 2401), ('exploration agency', 218), ('this phenomenon', 664), ('news conference', 30695), ('chokes out', 6), ('begins in', 2364), ('structure of', 3586), ('or man', 104), ('natural athleticism', 6), ('ousted former', 161), ('home cooks', 125), ('to his', 116775), ('the mountain', 6931), ('in historyabout', 2), ('denied due', 29), ('mr obama', 54345), ('upgraded the', 512), ('within a', 19985), ('high on', 4246), ('than 100000', 5357), ('blue diamond', 161), ('ap indonesian', 38), ('ride sport', 1), ('sexual violence', 1052), ('to sustain', 4161), ('as freddy', 21), ('in global', 5473), ('has filed', 3645), ('artist adds', 4), ('southern afghanistan', 5188), ('involved in', 62053), ('will use', 7822), ('we were', 44037), ('would like', 24319), ('opposition now', 49), ('creating the', 3178), ('kind has', 79), ('gatwick as', 20), ('in fukuoka', 54), ('father s', 11599), ('measure of', 10670), ('the airline', 15351), ('that are', 71176), ('race of', 1972), ('for newcomers', 129), ('advisors to', 378), ('term include', 6), ('foursquare a', 14), ('news service', 2790), ('2009 and', 13103), ('classic black', 46), ('reports and', 3486), ('and responsibilities', 876), ('that saleh', 30), ('saleh ahmed', 4), ('news reports', 4996), ('the psa', 291), ('flexibility and', 1141), ('admission of', 1360)]\n",
      "--- 938.5050921440125 seconds ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "print(\n",
    "    twoWordCountRDD\n",
    "#     .collect()\n",
    "    .take(100)\n",
    ")\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c6a2710",
   "metadata": {},
   "source": [
    "5. Print the two combined words that are the median in term of number of the appearances.  \n",
    "First we map each tuple from the word count RDD above into tuple with the number of appearances as the key and the string as value  \n",
    "ReduceKey to concat all the string having the same number of appearances. Then we sort them by key\n",
    "We use zipWithIndex to map each tuple with the correct index in the sorted result\n",
    "Finaly we can take the middle element from the above RDD result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "021bd781",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 53:=====================================================>(123 + 1) / 124]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[((7070, 'a model'), 6768)]\n",
      "--- 6431.71009349823 seconds ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "twoWordByAppearanceRDD = (\n",
    "    twoWordCountRDD\n",
    "    .map(lambda x: (x[1], x[0]))\n",
    "    .reduceByKey(lambda a, b: a + b)\n",
    "    .sortBy(lambda x: x[0])\n",
    ")\n",
    "median = math.floor(twoWordByAppearanceRDD.count() / 2)\n",
    "print(\n",
    "    twoWordByAppearanceRDD\n",
    "    .zipWithIndex()\n",
    "    .filter(lambda x: x[1] == median)\n",
    "    .top(1)\n",
    ")\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c48577f2",
   "metadata": {},
   "source": [
    "The result is 'a model' which appear at 7070 times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83919fd1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
