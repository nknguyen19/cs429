{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "22dabaf3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/12/28 13:55:39 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('spark.app.name', 'Prediction'),\n",
       " ('spark.driver.extraJavaOptions',\n",
       "  '-XX:+IgnoreUnrecognizedVMOptions --add-opens=java.base/java.lang=ALL-UNNAMED --add-opens=java.base/java.lang.invoke=ALL-UNNAMED --add-opens=java.base/java.lang.reflect=ALL-UNNAMED --add-opens=java.base/java.io=ALL-UNNAMED --add-opens=java.base/java.net=ALL-UNNAMED --add-opens=java.base/java.nio=ALL-UNNAMED --add-opens=java.base/java.util=ALL-UNNAMED --add-opens=java.base/java.util.concurrent=ALL-UNNAMED --add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.cs=ALL-UNNAMED --add-opens=java.base/sun.security.action=ALL-UNNAMED --add-opens=java.base/sun.util.calendar=ALL-UNNAMED --add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED'),\n",
       " ('spark.master', 'spark://master:7077'),\n",
       " ('spark.driver.host', 'master'),\n",
       " ('spark.app.id', 'app-20221228135540-0001'),\n",
       " ('spark.app.startTime', '1672235739245'),\n",
       " ('spark.executor.id', 'driver'),\n",
       " ('spark.app.submitTime', '1672235739007'),\n",
       " ('spark.driver.port', '44003'),\n",
       " ('spark.rdd.compress', 'True'),\n",
       " ('spark.executor.extraJavaOptions',\n",
       "  '-XX:+IgnoreUnrecognizedVMOptions --add-opens=java.base/java.lang=ALL-UNNAMED --add-opens=java.base/java.lang.invoke=ALL-UNNAMED --add-opens=java.base/java.lang.reflect=ALL-UNNAMED --add-opens=java.base/java.io=ALL-UNNAMED --add-opens=java.base/java.net=ALL-UNNAMED --add-opens=java.base/java.nio=ALL-UNNAMED --add-opens=java.base/java.util=ALL-UNNAMED --add-opens=java.base/java.util.concurrent=ALL-UNNAMED --add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.cs=ALL-UNNAMED --add-opens=java.base/sun.security.action=ALL-UNNAMED --add-opens=java.base/sun.util.calendar=ALL-UNNAMED --add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED'),\n",
       " ('spark.serializer.objectStreamReset', '100'),\n",
       " ('spark.submit.pyFiles', ''),\n",
       " ('spark.submit.deployMode', 'client'),\n",
       " ('spark.ui.showConsoleProgress', 'true')]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark import SparkContext, SparkConf\n",
    "conf = SparkConf().setMaster('spark://master:7077').setAppName('Prediction')\n",
    "sc = SparkContext(conf=conf)\n",
    "sc.setLogLevel('ERROR')\n",
    "sc.version\n",
    "sc.getConf().getAll()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93a0b896",
   "metadata": {},
   "source": [
    "Load training dataset and preprocess the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "187d8490",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "from itertools import islice\n",
    "\n",
    "# get the header and map with the column index for fast access\n",
    "header = (\n",
    "    sc\n",
    "#     .textFile('data/sample.csv', 8)\n",
    "    .textFile('data/train.csv', 8)\n",
    "    .take(1)[0]\n",
    "    .split(',')[1:]\n",
    ")\n",
    "\n",
    "headerMap = {}\n",
    "for i in range(len(header)):\n",
    "    headerMap[header[i]] = i\n",
    "    \n",
    "def parseFloat(x):\n",
    "    try:\n",
    "        return float(x)\n",
    "    except:\n",
    "        return x\n",
    "\n",
    "trainRDD = (\n",
    "    sc\n",
    "    .textFile('data/train.csv', 8)\n",
    "    .mapPartitionsWithIndex(\n",
    "        lambda index, it: islice(it, 1, None) if index == 0 else it # remove header line\n",
    "    )\n",
    "    .map(lambda x: x.split(','))\n",
    "    .map(lambda x: x[1:]) # remove id column\n",
    "    .map(lambda x: [parseFloat(i) for i in x])\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f23fdf65",
   "metadata": {},
   "source": [
    "Process the columns with continuous values  \n",
    "Cast and fitler out the valid value from each column  \n",
    "Since our label is also continuous so I divided it into 8 ranges based on the minimun and maximum values: (-inf, 100000], (100000, 200000], ... , (700000, inf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "13ec4e95",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "import math \n",
    "\n",
    "minNumberOfSamples = 10\n",
    "\n",
    "continuousFeatures = [\n",
    "    'LotFrontage', \n",
    "    'LotArea', \n",
    "    'MasVnrArea', \n",
    "    'BsmtFinSF1',\n",
    "    'BsmtFinSF2',\n",
    "    'BsmtUnfSF',\n",
    "    'TotalBsmtSF',\n",
    "    '1stFlrSF',\n",
    "    '2ndFlrSF',\n",
    "    'LowQualFinSF',\n",
    "    'GrLivArea',\n",
    "    'TotRmsAbvGrd',\n",
    "    'GarageArea',\n",
    "    'WoodDeckSF',\n",
    "    'OpenPorchSF',\n",
    "    'EnclosedPorch',\n",
    "    '3SsnPorch',\n",
    "    'ScreenPorch',\n",
    "    'PoolArea',\n",
    "    'MiscVal',\n",
    "    'MoSold',\n",
    "] \n",
    "\n",
    "labels = [100000, 200000, 300000, 400000, 500000, 600000, 700000, float('inf')]\n",
    "\n",
    "def parse(x):\n",
    "    for feature in continuousFeatures:\n",
    "        if not isinstance(x[headerMap[feature]], float):\n",
    "            x[headerMap[feature]] = 0\n",
    "    return x\n",
    "\n",
    "trainRDD = trainRDD.map(lambda x: parse(x))\n",
    "\n",
    "data = trainRDD.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c5d4417",
   "metadata": {},
   "source": [
    "# Decision Tree. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "29f9bac3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for feature in continuousFeatures:\n",
    "#     for x in data:\n",
    "#         if not isinstance(x[headerMap[feature]], float):\n",
    "#             x[headerMap[feature]] = 0\n",
    "import statistics\n",
    "\n",
    "# calculate the entropy of the input dataset\n",
    "def entropy(data):\n",
    "    # we count the appearances of each label in the dataset\n",
    "    count = {}\n",
    "    for x in data:\n",
    "        for label in labels:\n",
    "            if x[-1] <= label:\n",
    "                count[label] = count.get(label, 0) + 1\n",
    "                break\n",
    "    ret = 0\n",
    "    # calculate -sum(p_i * log(2, p_i))\n",
    "    for key,value in count.items():\n",
    "        x = value / len(data)\n",
    "        ret -= x * math.log(x, 2)\n",
    "    return ret\n",
    "\n",
    "# calculate the variance of a dataset\n",
    "def var(data):\n",
    "    data = [x[-1] for x in data]\n",
    "    mean = sum(data) / len(data)\n",
    "    return sum((i - mean) ** 2 for i in data) / len(data)\n",
    "    \n",
    "# find all possible split points of a feature in an input dataset      \n",
    "def getSplitPoints(data, feature):\n",
    "    if feature in continuousFeatures:\n",
    "        # If this feature is continuous, \n",
    "        # return only one split point for easiness, \n",
    "        # which the the median of this feature value \n",
    "        split_point = statistics.median([x[headerMap[feature]] for x in data])\n",
    "#         maxVal = max([x[headerMap[feature]] for x in data])\n",
    "#         minVal = min([x[headerMap[feature]] for x in data])\n",
    "        return [split_point, float('inf')] # (-inf, median] and (median, inf)\n",
    "    else:\n",
    "        # If this feature has discrete values,\n",
    "        # return the set of all the possible values\n",
    "        return set([x[headerMap[feature]] for x in data])\n",
    "\n",
    "# split the input dataset into two by a feature with a split_point\n",
    "def splitData(data, feature, split_point):\n",
    "    left = [] # left splitted dataset\n",
    "    right = [] # right splitted dataset\n",
    "    \n",
    "    # criteria for splitting\n",
    "    p = (\n",
    "        lambda x: x[headerMap[feature]] <= split_point if feature in continuousFeatures\n",
    "        else lambda x: x[headerMap[feature]] == split_point\n",
    "    )\n",
    "    \n",
    "    for x in data:\n",
    "        if p(x):\n",
    "            left.append(x)\n",
    "        else:\n",
    "            right.append(x)\n",
    "    \n",
    "    return left, right\n",
    "\n",
    "# find the best split of the dataset from all features\n",
    "def findBestSplit(data, features):\n",
    "    # best feature to split, best split point to split and best information purity\n",
    "    best_feature, best_split, best_purity = -1, -1, -1\n",
    "    \n",
    "    # for each feature, find its possible split points and calculate each purity to find the highest one\n",
    "    for feature in features:\n",
    "        split_points = getSplitPoints(data, feature)\n",
    "        for split_point in split_points:\n",
    "            left, right = splitData(data, feature, split_point)\n",
    "            if len(left) == 0 or len(right) == 0:\n",
    "                continue\n",
    "            purity = len(data) * var(data) - (len(left) * var(left) + len(right) * var(right))\n",
    "#             gain = (\n",
    "#                 entropy(data) \n",
    "#                 - len(left) / len(data) * entropy(left)\n",
    "#                 - len(right) / len(data) * entropy(right)\n",
    "#             )\n",
    "            if purity > best_purity:\n",
    "                best_purity, best_split, best_feature = purity, split_point, feature\n",
    "    \n",
    "    return best_feature, best_split\n",
    "\n",
    "# complete process of splitting dataset\n",
    "def processSplit(data, features):\n",
    "    feature, split_point = findBestSplit(data, features)\n",
    "    left, right = splitData(data, feature, split_point)\n",
    "    return feature, split_point, left, right\n",
    "\n",
    "# incase the node cannot be splitted, \n",
    "# assign the label to the node with the most common label appear in that node\n",
    "def findMostCommon(data):\n",
    "    count = {}\n",
    "    \n",
    "    for x in data:\n",
    "        for label in labels:\n",
    "            if x[-1] <= label:\n",
    "                count[label] = count.get(label, 0) + 1\n",
    "                break\n",
    "    most_common = -1\n",
    "    for key, value in count.items():\n",
    "        if most_common == -1 or value > count[most_common]:\n",
    "            most_common = key\n",
    "    \n",
    "    return most_common"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b5e0e2d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# a node inside the desicion tree\n",
    "class Node:\n",
    "    def __init__(self, isLeaf, feature, split_point=None, left=None, right=None):\n",
    "        self.isLeaf = isLeaf # whether this is a leaf node or not\n",
    "        if isLeaf:\n",
    "            self.label = feature # the label of the leaf node\n",
    "        else:\n",
    "            self.feature = feature # feature to split\n",
    "            self.split_point = split_point # split point of feature to split\n",
    "            self.left = left # left splitted node\n",
    "            self.right = right # right splitted node\n",
    "        \n",
    "class DecisionTree:\n",
    "    def __init__(self, data, features):\n",
    "        self.root = None\n",
    "        self.build(data, features)\n",
    "    \n",
    "    def build(self, data, features):\n",
    "        \n",
    "        # if the input dataset has little record\n",
    "        # stop splitting and assign the label to that node as the average of all candidates\n",
    "        if len(data) <= minNumberOfSamples:\n",
    "            avg = sum([x[-1] for x in data]) / len(data)\n",
    "            self.root = Node(True, avg)\n",
    "        \n",
    "        # begin to split the current node\n",
    "        else:\n",
    "            feature, split_point, left, right = processSplit(data, features)\n",
    "            \n",
    "            # if all data goes to left node or right node,\n",
    "            # set this node to be a leaf node with label as the most common label of all candidates\n",
    "            if len(left) == 0:\n",
    "                self.root = Node(True, findMostCommon(right))\n",
    "            elif len(right) == 0:\n",
    "                self.root = Node(True, findMostCommon(left))\n",
    "            \n",
    "            # continue to split the left node and right node\n",
    "            else:\n",
    "                left_node = DecisionTree(left, features)\n",
    "                right_node = DecisionTree(right, features)\n",
    "                self.root = Node(False, feature, split_point, left_node, right_node)\n",
    "            \n",
    "def predict(item, node):\n",
    "    if node.isLeaf:\n",
    "        return node.label\n",
    "    criteria = (\n",
    "        lambda x: x[headerMap[node.feature]] <= node.split_point if node.feature in continuousFeatures\n",
    "        else lambda x: x[headerMap[node.feature]] == node.split_point\n",
    "    )\n",
    "    if criteria(item):\n",
    "        return predict(item, node.left.root)\n",
    "    else :\n",
    "        return predict(item, node.right.root)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "21951e9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "tree = DecisionTree(data, header)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "14620cfa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predict for house id 1260 is 58671.42857142857\n",
      "Predict for house id 1261 is 97480.0\n",
      "Predict for house id 1262 is 58671.42857142857\n",
      "Predict for house id 1263 is 107500.0\n",
      "Predict for house id 1264 is 121777.77777777778\n",
      "Predict for house id 1265 is 107500.0\n",
      "Predict for house id 1266 is 58671.42857142857\n",
      "Predict for house id 1267 is 121777.77777777778\n",
      "Predict for house id 1268 is 107500.0\n",
      "Predict for house id 1269 is 58671.42857142857\n",
      "Predict for house id 1270 is 58671.42857142857\n",
      "Predict for house id 1271 is 58671.42857142857\n",
      "Predict for house id 1272 is 107500.0\n",
      "Predict for house id 1273 is 58671.42857142857\n",
      "Predict for house id 1274 is 58671.42857142857\n",
      "Predict for house id 1275 is 58671.42857142857\n",
      "Predict for house id 1276 is 121777.77777777778\n",
      "Predict for house id 1277 is 58671.42857142857\n",
      "Predict for house id 1278 is 107500.0\n",
      "Predict for house id 1279 is 58671.42857142857\n",
      "Predict for house id 1280 is 121777.77777777778\n",
      "Predict for house id 1281 is 97480.0\n",
      "Predict for house id 1282 is 58671.42857142857\n",
      "Predict for house id 1283 is 58671.42857142857\n",
      "Predict for house id 1284 is 121777.77777777778\n",
      "Predict for house id 1285 is 121777.77777777778\n",
      "Predict for house id 1286 is 121777.77777777778\n",
      "Predict for house id 1287 is 58671.42857142857\n",
      "Predict for house id 1288 is 97480.0\n",
      "Predict for house id 1289 is 58671.42857142857\n",
      "Predict for house id 1290 is 107500.0\n",
      "Predict for house id 1291 is 58671.42857142857\n",
      "Predict for house id 1292 is 58671.42857142857\n",
      "Predict for house id 1293 is 125875.0\n",
      "Predict for house id 1294 is 58671.42857142857\n",
      "Predict for house id 1295 is 121777.77777777778\n",
      "Predict for house id 1296 is 58671.42857142857\n",
      "Predict for house id 1297 is 58671.42857142857\n",
      "Predict for house id 1298 is 58671.42857142857\n",
      "Predict for house id 1299 is 58671.42857142857\n",
      "Predict for house id 1300 is 58671.42857142857\n",
      "Predict for house id 1301 is 58671.42857142857\n",
      "Predict for house id 1302 is 58671.42857142857\n",
      "Predict for house id 1303 is 58671.42857142857\n",
      "Predict for house id 1304 is 107500.0\n",
      "Predict for house id 1305 is 125875.0\n",
      "Predict for house id 1306 is 58671.42857142857\n",
      "Predict for house id 1307 is 107500.0\n",
      "Predict for house id 1308 is 58671.42857142857\n",
      "Predict for house id 1309 is 58671.42857142857\n",
      "Predict for house id 1310 is 58671.42857142857\n",
      "Predict for house id 1311 is 58671.42857142857\n",
      "Predict for house id 1312 is 58671.42857142857\n",
      "Predict for house id 1313 is 96628.57142857143\n",
      "Predict for house id 1314 is 107500.0\n",
      "Predict for house id 1315 is 58671.42857142857\n",
      "Predict for house id 1316 is 58671.42857142857\n",
      "Predict for house id 1317 is 107500.0\n",
      "Predict for house id 1318 is 107500.0\n",
      "Predict for house id 1319 is 107500.0\n",
      "Predict for house id 1320 is 58671.42857142857\n",
      "Predict for house id 1321 is 58671.42857142857\n",
      "Predict for house id 1322 is 58671.42857142857\n",
      "Predict for house id 1323 is 58671.42857142857\n",
      "Predict for house id 1324 is 58671.42857142857\n",
      "Predict for house id 1325 is 107500.0\n",
      "Predict for house id 1326 is 121777.77777777778\n",
      "Predict for house id 1327 is 58671.42857142857\n",
      "Predict for house id 1328 is 58671.42857142857\n",
      "Predict for house id 1329 is 125875.0\n",
      "Predict for house id 1330 is 125875.0\n",
      "Predict for house id 1331 is 107500.0\n",
      "Predict for house id 1332 is 58671.42857142857\n",
      "Predict for house id 1333 is 58671.42857142857\n",
      "Predict for house id 1334 is 97480.0\n",
      "Predict for house id 1335 is 58671.42857142857\n",
      "Predict for house id 1336 is 58671.42857142857\n",
      "Predict for house id 1337 is 107500.0\n",
      "Predict for house id 1338 is 97480.0\n",
      "Predict for house id 1339 is 58671.42857142857\n",
      "Predict for house id 1340 is 58671.42857142857\n",
      "Predict for house id 1341 is 121777.77777777778\n",
      "Predict for house id 1342 is 58671.42857142857\n",
      "Predict for house id 1343 is 107500.0\n",
      "Predict for house id 1344 is 121777.77777777778\n",
      "Predict for house id 1345 is 121777.77777777778\n",
      "Predict for house id 1346 is 121777.77777777778\n",
      "Predict for house id 1347 is 107500.0\n",
      "Predict for house id 1348 is 107500.0\n",
      "Predict for house id 1349 is 58671.42857142857\n",
      "Predict for house id 1350 is 58671.42857142857\n",
      "Predict for house id 1351 is 121777.77777777778\n",
      "Predict for house id 1352 is 58671.42857142857\n",
      "Predict for house id 1353 is 121777.77777777778\n",
      "Predict for house id 1354 is 107500.0\n",
      "Predict for house id 1355 is 58671.42857142857\n",
      "Predict for house id 1356 is 58671.42857142857\n",
      "Predict for house id 1357 is 58671.42857142857\n",
      "Predict for house id 1358 is 58671.42857142857\n",
      "Predict for house id 1359 is 58671.42857142857\n",
      "Predict for house id 1360 is 58671.42857142857\n",
      "Predict for house id 1361 is 58671.42857142857\n",
      "Predict for house id 1362 is 58671.42857142857\n",
      "Predict for house id 1363 is 121777.77777777778\n",
      "Predict for house id 1364 is 58671.42857142857\n",
      "Predict for house id 1365 is 58671.42857142857\n",
      "Predict for house id 1366 is 58671.42857142857\n",
      "Predict for house id 1367 is 58671.42857142857\n",
      "Predict for house id 1368 is 58671.42857142857\n",
      "Predict for house id 1369 is 58671.42857142857\n",
      "Predict for house id 1370 is 58671.42857142857\n",
      "Predict for house id 1371 is 58671.42857142857\n",
      "Predict for house id 1372 is 58671.42857142857\n",
      "Predict for house id 1373 is 58671.42857142857\n",
      "Predict for house id 1374 is 107500.0\n",
      "Predict for house id 1375 is 96628.57142857143\n",
      "Predict for house id 1376 is 107500.0\n",
      "Predict for house id 1377 is 58671.42857142857\n",
      "Predict for house id 1378 is 58671.42857142857\n",
      "Predict for house id 1379 is 58671.42857142857\n",
      "Predict for house id 1380 is 58671.42857142857\n",
      "Predict for house id 1381 is 58671.42857142857\n",
      "Predict for house id 1382 is 58671.42857142857\n",
      "Predict for house id 1383 is 58671.42857142857\n",
      "Predict for house id 1384 is 121777.77777777778\n",
      "Predict for house id 1385 is 58671.42857142857\n",
      "Predict for house id 1386 is 58671.42857142857\n",
      "Predict for house id 1387 is 86951.375\n",
      "Predict for house id 1388 is 58671.42857142857\n",
      "Predict for house id 1389 is 58671.42857142857\n",
      "Predict for house id 1390 is 58671.42857142857\n",
      "Predict for house id 1391 is 58671.42857142857\n",
      "Predict for house id 1392 is 107500.0\n",
      "Predict for house id 1393 is 58671.42857142857\n",
      "Predict for house id 1394 is 58671.42857142857\n",
      "Predict for house id 1395 is 58671.42857142857\n",
      "Predict for house id 1396 is 107500.0\n",
      "Predict for house id 1397 is 58671.42857142857\n",
      "Predict for house id 1398 is 96628.57142857143\n",
      "Predict for house id 1399 is 58671.42857142857\n",
      "Predict for house id 1400 is 97480.0\n",
      "Predict for house id 1401 is 121777.77777777778\n",
      "Predict for house id 1402 is 58671.42857142857\n",
      "Predict for house id 1403 is 107500.0\n",
      "Predict for house id 1404 is 58671.42857142857\n",
      "Predict for house id 1405 is 58671.42857142857\n",
      "Predict for house id 1406 is 58671.42857142857\n",
      "Predict for house id 1407 is 58671.42857142857\n",
      "Predict for house id 1408 is 58671.42857142857\n",
      "Predict for house id 1409 is 58671.42857142857\n",
      "Predict for house id 1410 is 97480.0\n",
      "Predict for house id 1411 is 58671.42857142857\n",
      "Predict for house id 1412 is 121777.77777777778\n",
      "Predict for house id 1413 is 58671.42857142857\n",
      "Predict for house id 1414 is 97480.0\n",
      "Predict for house id 1415 is 121777.77777777778\n",
      "Predict for house id 1416 is 58671.42857142857\n",
      "Predict for house id 1417 is 121777.77777777778\n",
      "Predict for house id 1418 is 58671.42857142857\n",
      "Predict for house id 1419 is 58671.42857142857\n",
      "Predict for house id 1420 is 97480.0\n",
      "Predict for house id 1421 is 58671.42857142857\n",
      "Predict for house id 1422 is 97480.0\n",
      "Predict for house id 1423 is 58671.42857142857\n",
      "Predict for house id 1424 is 97480.0\n",
      "Predict for house id 1425 is 58671.42857142857\n",
      "Predict for house id 1426 is 107500.0\n",
      "Predict for house id 1427 is 58671.42857142857\n",
      "Predict for house id 1428 is 58671.42857142857\n",
      "Predict for house id 1429 is 58671.42857142857\n",
      "Predict for house id 1430 is 121777.77777777778\n",
      "Predict for house id 1431 is 97480.0\n",
      "Predict for house id 1432 is 58671.42857142857\n",
      "Predict for house id 1433 is 58671.42857142857\n",
      "Predict for house id 1434 is 125875.0\n",
      "Predict for house id 1435 is 58671.42857142857\n",
      "Predict for house id 1436 is 107500.0\n",
      "Predict for house id 1437 is 58671.42857142857\n",
      "Predict for house id 1438 is 58671.42857142857\n",
      "Predict for house id 1439 is 58671.42857142857\n",
      "Predict for house id 1440 is 58671.42857142857\n",
      "Predict for house id 1441 is 58671.42857142857\n",
      "Predict for house id 1442 is 58671.42857142857\n",
      "Predict for house id 1443 is 58671.42857142857\n",
      "Predict for house id 1444 is 125875.0\n",
      "Predict for house id 1445 is 107500.0\n",
      "Predict for house id 1446 is 58671.42857142857\n",
      "Predict for house id 1447 is 58671.42857142857\n",
      "Predict for house id 1448 is 58671.42857142857\n",
      "Predict for house id 1449 is 58671.42857142857\n",
      "Predict for house id 1450 is 58671.42857142857\n",
      "Predict for house id 1451 is 97480.0\n",
      "Predict for house id 1452 is 107500.0\n",
      "Predict for house id 1453 is 58671.42857142857\n",
      "Predict for house id 1454 is 107500.0\n",
      "Predict for house id 1455 is 97480.0\n",
      "Predict for house id 1456 is 125875.0\n",
      "Predict for house id 1457 is 58671.42857142857\n",
      "Predict for house id 1458 is 97480.0\n",
      "Predict for house id 1459 is 58671.42857142857\n",
      "Predict for house id 1460 is 58671.42857142857\n"
     ]
    }
   ],
   "source": [
    "testData = (\n",
    "    sc\n",
    "    .textFile('data/test.csv', 8)\n",
    "    .mapPartitionsWithIndex(\n",
    "        lambda index, it: islice(it, 1, None) if index == 0 else it # remove header line\n",
    "    )\n",
    "    .map(lambda x: x.split(','))\n",
    "    .map(lambda x: [parseFloat(i) for i in x])\n",
    "    .map(lambda x: parse(x))\n",
    "    .collect()\n",
    ")\n",
    "\n",
    "for row in testData:\n",
    "    y_predict = predict(row, tree.root)\n",
    "    print(f'Predict for house id {int(row[0])} is {y_predict}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8d18eff",
   "metadata": {},
   "source": [
    "# PLANET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6fbe2b3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialization: Identifies all the attribute values which need to be considered for splits\n",
    "split_points = {}\n",
    "equi_depth = math.ceil(len(data) / 5)\n",
    "\n",
    "for feature in header[:-1]:\n",
    "    split_points[feature] = []\n",
    "    \n",
    "    # for continuous feature \n",
    "    # compute the approximate equi-depth histogram\n",
    "    # and find 4 split points to split data into equal part\n",
    "    if feature in continuousFeatures:\n",
    "        feature_data = sorted([x[headerMap[feature]] for x in data])\n",
    "        count = 0\n",
    "        for x in feature_data:\n",
    "            count += 1\n",
    "            if count >= equi_depth:\n",
    "                split_points[feature].append(x)\n",
    "                count = 0\n",
    "        split_points[feature].append(float('inf'))\n",
    "        \n",
    "    # for categorical feature, indentify the set of all possible values\n",
    "    else:\n",
    "        split_points[feature] = list(set([\n",
    "            x[headerMap[feature]] for x in data\n",
    "        ]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ce05f273",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'MSSubClass': [160.0,\n",
       "  70.0,\n",
       "  40.0,\n",
       "  75.0,\n",
       "  45.0,\n",
       "  80.0,\n",
       "  50.0,\n",
       "  20.0,\n",
       "  85.0,\n",
       "  180.0,\n",
       "  30.0,\n",
       "  120.0,\n",
       "  90.0,\n",
       "  60.0,\n",
       "  190.0],\n",
       " 'MSZoning': ['RM', 'RH', 'C (all)', 'RL', 'FV'],\n",
       " 'LotFrontage': [24.0, 60.0, 70.0, 80.0, inf],\n",
       " 'LotArea': [7100.0, 8777.0, 10200.0, 12168.0, inf],\n",
       " 'Street': ['Grvl', 'Pave'],\n",
       " 'Alley': ['NA', 'Pave', 'Grvl'],\n",
       " 'LotShape': ['IR3', 'IR2', 'IR1', 'Reg'],\n",
       " 'LandContour': ['Bnk', 'Low', 'Lvl', 'HLS'],\n",
       " 'Utilities': ['NoSeWa', 'AllPub'],\n",
       " 'LotConfig': ['Corner', 'FR3', 'Inside', 'CulDSac', 'FR2'],\n",
       " 'LandSlope': ['Sev', 'Mod', 'Gtl'],\n",
       " 'Neighborhood': ['OldTown',\n",
       "  'Crawfor',\n",
       "  'SawyerW',\n",
       "  'StoneBr',\n",
       "  'IDOTRR',\n",
       "  'NAmes',\n",
       "  'BrDale',\n",
       "  'MeadowV',\n",
       "  'BrkSide',\n",
       "  'Somerst',\n",
       "  'Blmngtn',\n",
       "  'Gilbert',\n",
       "  'SWISU',\n",
       "  'Mitchel',\n",
       "  'Veenker',\n",
       "  'CollgCr',\n",
       "  'Blueste',\n",
       "  'Timber',\n",
       "  'NPkVill',\n",
       "  'ClearCr',\n",
       "  'NoRidge',\n",
       "  'NridgHt',\n",
       "  'NWAmes',\n",
       "  'Sawyer',\n",
       "  'Edwards'],\n",
       " 'Condition1': ['Feedr',\n",
       "  'Norm',\n",
       "  'RRNn',\n",
       "  'PosN',\n",
       "  'RRNe',\n",
       "  'RRAe',\n",
       "  'Artery',\n",
       "  'PosA',\n",
       "  'RRAn'],\n",
       " 'Condition2': ['Feedr',\n",
       "  'Norm',\n",
       "  'RRNn',\n",
       "  'PosN',\n",
       "  'RRAe',\n",
       "  'Artery',\n",
       "  'PosA',\n",
       "  'RRAn'],\n",
       " 'BldgType': ['Duplex', 'Twnhs', '2fmCon', '1Fam', 'TwnhsE'],\n",
       " 'HouseStyle': ['2Story',\n",
       "  'SLvl',\n",
       "  '2.5Unf',\n",
       "  'SFoyer',\n",
       "  '1.5Fin',\n",
       "  '1Story',\n",
       "  '1.5Unf',\n",
       "  '2.5Fin'],\n",
       " 'OverallQual': [1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0, 10.0],\n",
       " 'OverallCond': [1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0],\n",
       " 'YearBuilt': [1875.0,\n",
       "  1880.0,\n",
       "  1882.0,\n",
       "  1885.0,\n",
       "  1890.0,\n",
       "  1892.0,\n",
       "  1893.0,\n",
       "  1898.0,\n",
       "  1900.0,\n",
       "  1904.0,\n",
       "  1906.0,\n",
       "  1908.0,\n",
       "  1910.0,\n",
       "  1911.0,\n",
       "  1912.0,\n",
       "  1913.0,\n",
       "  1914.0,\n",
       "  1915.0,\n",
       "  1916.0,\n",
       "  1917.0,\n",
       "  1918.0,\n",
       "  1919.0,\n",
       "  1920.0,\n",
       "  1921.0,\n",
       "  1922.0,\n",
       "  1923.0,\n",
       "  1924.0,\n",
       "  1925.0,\n",
       "  1926.0,\n",
       "  1927.0,\n",
       "  1928.0,\n",
       "  1929.0,\n",
       "  1930.0,\n",
       "  1931.0,\n",
       "  1932.0,\n",
       "  1934.0,\n",
       "  1935.0,\n",
       "  1936.0,\n",
       "  1937.0,\n",
       "  1938.0,\n",
       "  1939.0,\n",
       "  1940.0,\n",
       "  1941.0,\n",
       "  1942.0,\n",
       "  1945.0,\n",
       "  1946.0,\n",
       "  1947.0,\n",
       "  1948.0,\n",
       "  1949.0,\n",
       "  1950.0,\n",
       "  1951.0,\n",
       "  1952.0,\n",
       "  1953.0,\n",
       "  1954.0,\n",
       "  1955.0,\n",
       "  1956.0,\n",
       "  1957.0,\n",
       "  1958.0,\n",
       "  1959.0,\n",
       "  1960.0,\n",
       "  1961.0,\n",
       "  1962.0,\n",
       "  1963.0,\n",
       "  1964.0,\n",
       "  1965.0,\n",
       "  1966.0,\n",
       "  1967.0,\n",
       "  1968.0,\n",
       "  1969.0,\n",
       "  1970.0,\n",
       "  1971.0,\n",
       "  1972.0,\n",
       "  1973.0,\n",
       "  1974.0,\n",
       "  1975.0,\n",
       "  1976.0,\n",
       "  1977.0,\n",
       "  1978.0,\n",
       "  1979.0,\n",
       "  1980.0,\n",
       "  1981.0,\n",
       "  1982.0,\n",
       "  1983.0,\n",
       "  1984.0,\n",
       "  1985.0,\n",
       "  1986.0,\n",
       "  1987.0,\n",
       "  1988.0,\n",
       "  1989.0,\n",
       "  1990.0,\n",
       "  1991.0,\n",
       "  1992.0,\n",
       "  1993.0,\n",
       "  1994.0,\n",
       "  1995.0,\n",
       "  1996.0,\n",
       "  1997.0,\n",
       "  1998.0,\n",
       "  1999.0,\n",
       "  2000.0,\n",
       "  2001.0,\n",
       "  2002.0,\n",
       "  2003.0,\n",
       "  2004.0,\n",
       "  2005.0,\n",
       "  2006.0,\n",
       "  2007.0,\n",
       "  2008.0,\n",
       "  2009.0,\n",
       "  2010.0],\n",
       " 'YearRemodAdd': [1950.0,\n",
       "  1951.0,\n",
       "  1952.0,\n",
       "  1953.0,\n",
       "  1954.0,\n",
       "  1955.0,\n",
       "  1956.0,\n",
       "  1957.0,\n",
       "  1958.0,\n",
       "  1959.0,\n",
       "  1960.0,\n",
       "  1961.0,\n",
       "  1962.0,\n",
       "  1963.0,\n",
       "  1964.0,\n",
       "  1965.0,\n",
       "  1966.0,\n",
       "  1967.0,\n",
       "  1968.0,\n",
       "  1969.0,\n",
       "  1970.0,\n",
       "  1971.0,\n",
       "  1972.0,\n",
       "  1973.0,\n",
       "  1974.0,\n",
       "  1975.0,\n",
       "  1976.0,\n",
       "  1977.0,\n",
       "  1978.0,\n",
       "  1979.0,\n",
       "  1980.0,\n",
       "  1981.0,\n",
       "  1982.0,\n",
       "  1983.0,\n",
       "  1984.0,\n",
       "  1985.0,\n",
       "  1986.0,\n",
       "  1987.0,\n",
       "  1988.0,\n",
       "  1989.0,\n",
       "  1990.0,\n",
       "  1991.0,\n",
       "  1992.0,\n",
       "  1993.0,\n",
       "  1994.0,\n",
       "  1995.0,\n",
       "  1996.0,\n",
       "  1997.0,\n",
       "  1998.0,\n",
       "  1999.0,\n",
       "  2000.0,\n",
       "  2001.0,\n",
       "  2002.0,\n",
       "  2003.0,\n",
       "  2004.0,\n",
       "  2005.0,\n",
       "  2006.0,\n",
       "  2007.0,\n",
       "  2008.0,\n",
       "  2009.0,\n",
       "  2010.0],\n",
       " 'RoofStyle': ['Hip', 'Gable', 'Shed', 'Gambrel', 'Mansard', 'Flat'],\n",
       " 'RoofMatl': ['Metal', 'WdShngl', 'Tar&Grv', 'CompShg', 'Membran', 'WdShake'],\n",
       " 'Exterior1st': ['ImStucc',\n",
       "  'Stone',\n",
       "  'Wd Sdng',\n",
       "  'Plywood',\n",
       "  'HdBoard',\n",
       "  'VinylSd',\n",
       "  'WdShing',\n",
       "  'AsbShng',\n",
       "  'Stucco',\n",
       "  'BrkFace',\n",
       "  'AsphShn',\n",
       "  'MetalSd',\n",
       "  'CemntBd',\n",
       "  'BrkComm'],\n",
       " 'Exterior2nd': ['ImStucc',\n",
       "  'Brk Cmn',\n",
       "  'Stone',\n",
       "  'Wd Sdng',\n",
       "  'Plywood',\n",
       "  'HdBoard',\n",
       "  'VinylSd',\n",
       "  'Stucco',\n",
       "  'AsbShng',\n",
       "  'CmentBd',\n",
       "  'BrkFace',\n",
       "  'Other',\n",
       "  'AsphShn',\n",
       "  'Wd Shng',\n",
       "  'MetalSd'],\n",
       " 'MasVnrType': ['None', 'NA', 'Stone', 'BrkCmn', 'BrkFace'],\n",
       " 'MasVnrArea': [0.0, 0.0, 16.0, 206.0, inf],\n",
       " 'ExterQual': ['Ex', 'Gd', 'TA', 'Fa'],\n",
       " 'ExterCond': ['Po', 'Gd', 'Ex', 'TA', 'Fa'],\n",
       " 'Foundation': ['BrkTil', 'Stone', 'CBlock', 'Wood', 'Slab', 'PConc'],\n",
       " 'BsmtQual': ['NA', 'Gd', 'Ex', 'TA', 'Fa'],\n",
       " 'BsmtCond': ['Po', 'NA', 'Gd', 'TA', 'Fa'],\n",
       " 'BsmtExposure': ['NA', 'Gd', 'Av', 'Mn', 'No'],\n",
       " 'BsmtFinType1': ['NA', 'GLQ', 'Unf', 'BLQ', 'Rec', 'ALQ', 'LwQ'],\n",
       " 'BsmtFinSF1': [0.0, 222.0, 524.0, 816.0, inf],\n",
       " 'BsmtFinType2': ['NA', 'GLQ', 'Unf', 'BLQ', 'Rec', 'ALQ', 'LwQ'],\n",
       " 'BsmtFinSF2': [0.0, 0.0, 0.0, 0.0, inf],\n",
       " 'BsmtUnfSF': [173.0, 378.0, 600.0, 894.0, inf],\n",
       " 'TotalBsmtSF': [755.0, 912.0, 1090.0, 1391.0, inf],\n",
       " 'Heating': ['Wall', 'Grav', 'GasW', 'GasA', 'OthW'],\n",
       " 'HeatingQC': ['Po', 'Gd', 'Ex', 'TA', 'Fa'],\n",
       " 'CentralAir': ['Y', 'N'],\n",
       " 'Electrical': ['FuseP', 'FuseA', 'Mix', 'SBrkr', 'FuseF'],\n",
       " '1stFlrSF': [848.0, 1001.0, 1180.0, 1479.0, inf],\n",
       " '2ndFlrSF': [0.0, 0.0, 441.0, 793.0, inf],\n",
       " 'LowQualFinSF': [0.0, 0.0, 0.0, 0.0, inf],\n",
       " 'GrLivArea': [1062.0, 1328.0, 1572.0, 1856.0, inf],\n",
       " 'BsmtFullBath': [0.0, 1.0, 2.0, 3.0],\n",
       " 'BsmtHalfBath': [0.0, 1.0, 2.0],\n",
       " 'FullBath': [0.0, 1.0, 2.0, 3.0],\n",
       " 'HalfBath': [0.0, 1.0, 2.0],\n",
       " 'BedroomAbvGr': [0.0, 1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 8.0],\n",
       " 'KitchenAbvGr': [0.0, 1.0, 2.0, 3.0],\n",
       " 'KitchenQual': ['Ex', 'Gd', 'TA', 'Fa'],\n",
       " 'TotRmsAbvGrd': [5.0, 6.0, 7.0, 8.0, inf],\n",
       " 'Functional': ['Maj1', 'Typ', 'Mod', 'Maj2', 'Min2', 'Sev', 'Min1'],\n",
       " 'Fireplaces': [0.0, 1.0, 2.0, 3.0],\n",
       " 'FireplaceQu': ['Po', 'NA', 'Gd', 'Ex', 'TA', 'Fa'],\n",
       " 'GarageType': ['Attchd',\n",
       "  'NA',\n",
       "  'Basment',\n",
       "  'CarPort',\n",
       "  'BuiltIn',\n",
       "  'Detchd',\n",
       "  '2Types'],\n",
       " 'GarageYrBlt': [1992.0,\n",
       "  1900.0,\n",
       "  1906.0,\n",
       "  1908.0,\n",
       "  1910.0,\n",
       "  1914.0,\n",
       "  1915.0,\n",
       "  1916.0,\n",
       "  1918.0,\n",
       "  1920.0,\n",
       "  1921.0,\n",
       "  1922.0,\n",
       "  1923.0,\n",
       "  1924.0,\n",
       "  1925.0,\n",
       "  1926.0,\n",
       "  1927.0,\n",
       "  1928.0,\n",
       "  1930.0,\n",
       "  1931.0,\n",
       "  1932.0,\n",
       "  1934.0,\n",
       "  1935.0,\n",
       "  1936.0,\n",
       "  1937.0,\n",
       "  1938.0,\n",
       "  1939.0,\n",
       "  1940.0,\n",
       "  1941.0,\n",
       "  1942.0,\n",
       "  1945.0,\n",
       "  1946.0,\n",
       "  1947.0,\n",
       "  1948.0,\n",
       "  1949.0,\n",
       "  1950.0,\n",
       "  1951.0,\n",
       "  1952.0,\n",
       "  1953.0,\n",
       "  1954.0,\n",
       "  1955.0,\n",
       "  1956.0,\n",
       "  1957.0,\n",
       "  1958.0,\n",
       "  1959.0,\n",
       "  1960.0,\n",
       "  1961.0,\n",
       "  1962.0,\n",
       "  1963.0,\n",
       "  1964.0,\n",
       "  1965.0,\n",
       "  1966.0,\n",
       "  1967.0,\n",
       "  1968.0,\n",
       "  1969.0,\n",
       "  1970.0,\n",
       "  1971.0,\n",
       "  1972.0,\n",
       "  1973.0,\n",
       "  1974.0,\n",
       "  1975.0,\n",
       "  1976.0,\n",
       "  1977.0,\n",
       "  1978.0,\n",
       "  1979.0,\n",
       "  1980.0,\n",
       "  1981.0,\n",
       "  1982.0,\n",
       "  1983.0,\n",
       "  1984.0,\n",
       "  1985.0,\n",
       "  1986.0,\n",
       "  'NA',\n",
       "  1987.0,\n",
       "  1989.0,\n",
       "  1990.0,\n",
       "  1991.0,\n",
       "  1988.0,\n",
       "  1993.0,\n",
       "  1994.0,\n",
       "  1995.0,\n",
       "  1996.0,\n",
       "  1997.0,\n",
       "  1998.0,\n",
       "  1999.0,\n",
       "  2000.0,\n",
       "  2001.0,\n",
       "  2002.0,\n",
       "  2003.0,\n",
       "  2004.0,\n",
       "  2005.0,\n",
       "  2006.0,\n",
       "  2007.0,\n",
       "  2008.0,\n",
       "  2009.0,\n",
       "  2010.0],\n",
       " 'GarageFinish': ['NA', 'Fin', 'Unf', 'RFn'],\n",
       " 'GarageCars': [0.0, 1.0, 2.0, 3.0, 4.0],\n",
       " 'GarageArea': [296.0, 440.0, 516.0, 616.0, inf],\n",
       " 'GarageQual': ['Po', 'NA', 'Gd', 'Ex', 'TA', 'Fa'],\n",
       " 'GarageCond': ['Po', 'NA', 'Gd', 'Ex', 'TA', 'Fa'],\n",
       " 'PavedDrive': ['Y', 'P', 'N'],\n",
       " 'WoodDeckSF': [0.0, 0.0, 104.0, 192.0, inf],\n",
       " 'OpenPorchSF': [0.0, 0.0, 40.0, 83.0, inf],\n",
       " 'EnclosedPorch': [0.0, 0.0, 0.0, 0.0, inf],\n",
       " '3SsnPorch': [0.0, 0.0, 0.0, 0.0, inf],\n",
       " 'ScreenPorch': [0.0, 0.0, 0.0, 0.0, inf],\n",
       " 'PoolArea': [0.0, 0.0, 0.0, 0.0, inf],\n",
       " 'PoolQC': ['Ex', 'NA', 'Gd', 'Fa'],\n",
       " 'Fence': ['NA', 'MnWw', 'MnPrv', 'GdPrv', 'GdWo'],\n",
       " 'MiscFeature': ['Othr', 'Gar2', 'NA', 'Shed'],\n",
       " 'MiscVal': [0.0, 0.0, 0.0, 0.0, inf],\n",
       " 'MoSold': [4.0, 6.0, 7.0, 8.0, inf],\n",
       " 'YrSold': [2006.0, 2007.0, 2008.0, 2009.0, 2010.0],\n",
       " 'SaleType': ['ConLI',\n",
       "  'WD',\n",
       "  'COD',\n",
       "  'ConLw',\n",
       "  'ConLD',\n",
       "  'CWD',\n",
       "  'Oth',\n",
       "  'New',\n",
       "  'Con'],\n",
       " 'SaleCondition': ['Normal',\n",
       "  'Alloca',\n",
       "  'Abnorml',\n",
       "  'Family',\n",
       "  'AdjLand',\n",
       "  'Partial']}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "split_points"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6359e365",
   "metadata": {},
   "source": [
    "### MapReduce Initialization Task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3ad28016",
   "metadata": {},
   "outputs": [],
   "source": [
    "nodes = {}\n",
    "\n",
    "def criteria(x, feature, value):\n",
    "    if feature in continuousFeatures:\n",
    "        if x[headerMap[feature]] <= value:\n",
    "            return True\n",
    "    else:\n",
    "        if x[headerMap[feature]] == value:\n",
    "            return True\n",
    "\n",
    "class PlanetNode:\n",
    "    def __init__(self, _id, feature, split_point, label=None):\n",
    "        self.id = _id # Node ID\n",
    "        self.label = label # Node label\n",
    "        if label:\n",
    "            self.label = label\n",
    "        else:\n",
    "            self.feature = feature # split feature\n",
    "            self.split_point = split_point # split value\n",
    "\n",
    "    # traverse a record to a deepest node and obtain its node ID\n",
    "    def traverse(self, x):\n",
    "        if self.label or not self.feature:\n",
    "            return self.id\n",
    "        \n",
    "        if criteria(x, self.feature, self.split_point):\n",
    "            return nodes[self.id * 2].traverse(x)\n",
    "        return nodes[self.id * 2 + 1].traverse(x)\n",
    "            \n",
    "def traverseTree(x, node):\n",
    "    return node.traverse(x)\n",
    "\n",
    "# find all possible splitting criteria (including split feature and split value) of a record\n",
    "def possibleSplit(x):\n",
    "    ret = []\n",
    "    for feature, values in split_points.items():\n",
    "        for value in values:\n",
    "            if criteria(x, feature, value):\n",
    "                ret.append((feature, value))\n",
    "                break;\n",
    "    return ret\n",
    "\n",
    "# compute the purity of a ndoe after splitting\n",
    "def purity(node, left):\n",
    "    p_node = node[2] - node[1] ** 2 / node[0]\n",
    "    p_left = left[2] - left[1] ** 2 / left[0]\n",
    "    right = (node[0] - left[0], node[1] - left[1], node[2] - left[2])\n",
    "    p_right = right[2] - right[1] ** 2 / right[0]\n",
    "    return p_node - p_left - p_right"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0c4d2e90",
   "metadata": {},
   "outputs": [],
   "source": [
    "nodes[0] = PlanetNode(1, None, None) # initialize the tree with one node"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "deeeca71",
   "metadata": {},
   "source": [
    "### MapReduce FindBestSplit Task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7372f291",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 5:=============================>                             (4 + 4) / 8]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best split for node id 1 is ('GarageCars', 3.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Mapper\n",
    "\n",
    "# map each record with a node ID\n",
    "# (nodeID, (n, s, q))\n",
    "split_nodes = (\n",
    "    trainRDD\n",
    "    .map(lambda x: (traverseTree(x, nodes[0]), (1, x[-1], x[-1] ** 2)))\n",
    "    .reduceByKey(lambda a, b: (a[0] + b[0], a[1] + b[1], a[2] + b[2]))\n",
    "    .collect()\n",
    ")\n",
    "\n",
    "# map each record with a spliting criteria and a nodeID\n",
    "# ((nodeID, (feature, split point)), (n, s, q))\n",
    "splitRDD = (\n",
    "    trainRDD\n",
    "    .flatMap(lambda x: \n",
    "        [(\n",
    "            (traverseTree(x, nodes[0]), i),\n",
    "            (1, x[-1], x[-1] ** 2)\n",
    "        ) \n",
    "        for i in possibleSplit(x)]\n",
    "    )\n",
    "    .reduceByKey(lambda a, b: (a[0] + b[0], a[1] + b[1], a[2] + b[2]))\n",
    ")\n",
    "\n",
    "# Reducer\n",
    "\n",
    "# find the best split in each node\n",
    "for node in split_nodes:\n",
    "    best_split = (\n",
    "        splitRDD\n",
    "        .filter(lambda x: x[0][0] == node[0])\n",
    "        .map(lambda x: (x[0], purity(node[1], x[1])))\n",
    "        .takeOrdered(1, lambda x: -x[1]) # take the split with highest purity\n",
    "    )\n",
    "    print(f'Best split for node id {node[0]} is {best_split[0][0][1]}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
